 [GitHub - GoldenLandForever/032002539](https://github.com/GoldenLandForever/032002539)

# 一、PSP表格

| Personal Software Process Stages         | 预估耗时 （分钟） | 实际耗时 （分钟） |
| ---------------------------------------- | ----------------- | ----------------- |
| 计划                                     | 120               | 60                |
| 估计这个任务需要多少时间                 | 5                 | 5                 |
| 开发                                     | 30                | 30                |
| 需求分析 (包括学习新技术)                | 5760              | 2880              |
| · 生成设计文档                           | 30                | 30                |
| · 设计复审                               | 5                 | 3                 |
| · 代码规范 (为目前的开发制 定合适的规范) | 5                 | 5                 |
| 具体设计                                 | 30                | 10                |
| · 具体编码                               | 2880              | 1440              |
| · 代码复审                               | 60                | 30                |
| 测试（自我测试，修改代 码，提交修改）    | 1440              | 2880              |
| 报告                                     | 60                | 60                |
| · 测试报告                               | 30                | 30                |
| 计算工作量                               | 10                | 5                 |
| 事后总结, 并提出过程改进 计划            | 10                | 10                |
| 合计                                     | 10475             | 7478              |

# 二、任务要求的实现

## 项目设计与技术栈

> 技术栈

爬虫部分：

- python

- selenium

- re

  

可视化部分：

- pyecharts
- pandas

> 项目设计

1.使用python爬取数据

2.将所爬取到的数据进行可视化处理

> 数据统计接口部分的性能改进。



![img](https://img-blog.csdnimg.cn/be1b03fbc5d54eda9bbfff15c6969296.png)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)



优化正则表达式来减少消耗时间

> 每日热点的实现思路

因为我不会算法，所以我用爬虫爬了百度疫情的每日热点来实现QAQ。

> 数据可视化界面的展示。

我所使用的爬虫技术速度较慢，爬取近两年的数据耗时量太大，故难以建立数据库，于是我直接将

每次爬取到的数据直接使用pyecharts与pandas进行可视化操作。

每一天的数据如图：

![img](https://img-blog.csdnimg.cn/a775a269e1b941e195195e6d3abd6ddc.png)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)

 ![img](https://img-blog.csdnimg.cn/693fe945b782415cb5516e8e2d3c5f34.png)![点击并拖拽以移动](data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==)



# 三、心得体会

本次作业对我的难度较大，我自认为能独立做到此地步已经心满意足了。这次作业让我受益匪浅，

不仅是对原本初一窍不通的爬虫的了解，还有对数据的处理，甚至还有对构建数据库，搭建前后端

的了解。我现在计划扩充我的知识面，希望下次作业能够有足够多的知识储备来加以解答。